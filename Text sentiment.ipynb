{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2DHR5kxCcr8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi2kfrXhQ1oi",
        "outputId": "ed1c05c4-0a50-4a76-e406-ecaa5789e5c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the sentence: i am not happy and joyful\n",
            "Synonyms for not are set()\n",
            "Synonyms for happy are {'happy'}\n",
            "Synonyms for joyful are {'joyful'}\n",
            "Sentiment Score: -1\n",
            "Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english')) - {'not', 'no', 'never'}\n",
        "    new_tokens = []\n",
        "    for token in tokens:\n",
        "        if token.lower() not in stop_words:\n",
        "            new_tokens.append(token)\n",
        "    return new_tokens\n",
        "\n",
        "def synonyms(word, pos='a'):\n",
        "    synonyms_set = set()\n",
        "    for synset in wn.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            if synset.pos() == pos:\n",
        "                synonyms_set.add(lemma.name().lower())\n",
        "    return synonyms_set\n",
        "\n",
        "\n",
        "def sentiment(text):\n",
        "    tokens = tokenize_text(text)\n",
        "    polarity=0\n",
        "    positive_pos = ['JJR', 'JJ', 'VB', 'JJS', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
        "    negative_pos = ['RB', 'RBR', 'RBS','JJ']\n",
        "    pos_tokens = pos_tag(tokens)\n",
        "    for token, pos in pos_tokens:\n",
        "        if token.lower() in positive_pos and pos in positive_pos:\n",
        "            polarity += 1\n",
        "        elif token.lower() in negative_pos and pos in negative_pos:\n",
        "            polarity -= 1\n",
        "        else:\n",
        "            synonyms_set = synonyms(token)\n",
        "            print(\"Synonyms for\", token, \"are\", synonyms_set)\n",
        "            for synonym in synonyms_set:\n",
        "                if synonym in positive_pos:\n",
        "                    polarity += 1\n",
        "                elif synonym in negative_pos:\n",
        "                    polarity -= 1\n",
        "                elif synonym in negative_words:\n",
        "                    polarity-=1\n",
        "    negative=False\n",
        "    for token in tokens:\n",
        "        if token in ['not', 'never', 'no',\"n't\"]:\n",
        "            negative = True\n",
        "        elif token in positive_words:\n",
        "            if negative:\n",
        "                polarity -= 1\n",
        "                negative = False\n",
        "            else:\n",
        "                polarity += 1\n",
        "        elif token in negative_words:\n",
        "            if negative:\n",
        "                polarity += 1\n",
        "                negative = False\n",
        "            else:\n",
        "                polarity -= 1\n",
        "\n",
        "    negative=False\n",
        "    for token in tokens:\n",
        "        if token in ['not', 'never', 'no']:\n",
        "            negative = True\n",
        "            polarity -=1\n",
        "    return polarity\n",
        "\n",
        "def sentiment_analysis(polarity):\n",
        "    if polarity > 0:\n",
        "        print(\"Sentiment: Positive\")\n",
        "    elif polarity == 0:\n",
        "        print(\"Sentiment: Neutral\")\n",
        "    else:\n",
        "        print(\"Sentiment: Negative\")\n",
        "\n",
        "def main():\n",
        "    text = input(\"Enter the sentence: \")\n",
        "    polarity = sentiment(text)\n",
        "    print(\"Sentiment Score:\", polarity)\n",
        "    sentiment_analysis(polarity)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    positive_words = ['love','like','good','delicious','joy','proud','sweet','amazing']\n",
        "    negative_words = ['not','bad','dislike',\"n't\",\"don't\",'unpleasant','foul','rude','offensive','disgusting','awful','cruel','hate']\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ncBbL45wtq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZpv_oPEQ16x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGdk6_iTQ2II"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zTGvDNnQ2e5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkqBqbYS0pHG"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
